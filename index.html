<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>COSC 102 - How to Test Your Code</title>
    <link rel="stylesheet" href="assets/css/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
    <header>
        <div class="logo">
            <h1>COSC 102 Testing Guide</h1>
        </div>
        <nav id="main-nav">
            <ul>
                <li><a href="#home" class="active" data-page="home"><i class="fas fa-home"></i> Home</a></li>
                <li><a href="#overview" data-page="overview"><i class="fas fa-map"></i> 4-Step Approach</a></li>
                <li><a href="#example1" data-page="example1"><i class="fas fa-1"></i> Example</a></li>
                <li><a href="#example2" data-page="example2"><i class="fas fa-2"></i> Example</a></li>
                <li><a href="#example3" data-page="example3"><i class="fas fa-3"></i> Example</a></li>
                <li><a href="#advanced" data-page="advanced"><i class="fas fa-code"></i> Advanced</a></li>
            </ul>
        </nav>
        <button id="theme-toggle">
            <i class="fas fa-moon"></i>
        </button>
    </header>
    
    <main>
        <!-- Home Page -->
        <section id="home" class="page active">
            <div class="hero">
                <div class="hero-content">
                    <h2>Learn How to Test Your Code</h2>
                    <p>A comprehensive guide for COSC 102 students</p>
                    <p class="authors">By Jonathan Cook, Haran Eiger, Hans Bressel</p>
                </div>
            </div>
            
            <div class="motivation">
                <h2>Testing Philosophy</h2>
                <div class="card-container">
                    <div class="card">
                        <div class="card-icon"><i class="fas fa-question-circle"></i></div>
                        <h3>Why</h3>
                        <div class="card-content">
                            <p>Have you ever been caught off guard by a bug with no clear origin or fix? The assignment is due in 20 minutes, panic sets in, and you know your grade is about to take a hit. Testing changes that.</p>

                            <p>By integrating test suites while writing your code, you create a clearer and more coherent understanding of what your program is doing, and when something goes wrong, you'll know exactly where to look.</p>

                            <p>Testing isn't just for catching mistakes, instead it gives you confidence that your code works as expected and helps document its intended behavior for yourself and others.</p>
                        </div>
                    </div>
                    <div class="card">
                        <div class="card-icon"><i class="fas fa-clock"></i></div>
                        <h3>When</h3>
                        <div class="card-content">
                            <p>You should start testing as soon as you begin outlining your code. The moment you understand what your program is supposed to achieve is the moment you can begin designing meaningful tests.</p>

                            <p>Testing early lets you identify edge cases and confirm that the core logic works as intended while you build. That way, if you refactor or update your code later, your pre-written tests serve as a safety net, quickly catching any unintended changes before they become serious problems.</p>

                            <p> </p>
                            <p> </p>
                            <p> </p>
                            <p> </p>
                            <p> </p>
                        </div>
                    </div>
                    <div class="card">
                        <div class="card-icon"><i class="fas fa-cogs"></i></div>
                        <h3>How</h3>
                        <div class="card-content">
                            <p>Ensure that you understand both the inputs and outputs of your code very clearly. Ask yourself: What are the boundaries of the input? What are the distinctions between different input categories?</p>

                            <p>Are all lines of code and all conditional branches being exercised by your tests? By consistently asking these kinds of questions, you'll define your input and output space thoroughly and ensure that every line of your code is doing exactly what it's supposed to.</p>

                            <p> </p>
                            <p> </p>
                            <p> </p>
                            <p> </p>
                            <p> </p>
                            <p> </p>
                            <p> </p>

                        </div>
                    </div>
                </div>
            </div>
            
            <div class="cta">
                <h2>Ready to Learn More?</h2>
                <button class="btn-primary" id="get-started">Get Started</button>
            </div>
        </section>
        
        <!-- 4-Step Overview Page -->
        <section id="overview" class="page">
            <div class="approach-intro">
                <h2>Our 4-Step Testing Approach</h2>
                <div class="intro-content">
                    <p>The testing approaches detailed in this project, Boundary Value Testing (BVT), Equivalence Class Testing (ECT), and Line/Branch Coverage, are designed to directly target the most common loop and boundary errors students encounter in COSC 102. These techniques were intentionally ordered to build progressively: starting with simple boundary testing, moving to strategies that partition the input or output space, and culminating in ensuring full line and branch coverage. Each method adds a new layer of insight into how thoroughly your code is tested.</p>
                    <p>This sequence provides a structural sweep of your code, ensuring it's not only functionally correct but also robust against edge cases and overlooked logic. To minimize redundancy in test cases, we introduced slight variations across the techniques, allowing students to achieve high coverage with relatively low effort.</p>
                </div>
            </div>
            <h2>The 4 Steps</h2>
            <div class="step-overview">
                <div class="step">
                    <div class="step-number">1</div>
                    <h3>Robust Boundary-Value Tests</h3>
                    <p>Filter valid vs invalid cases</p>
                    <button class="btn-secondary expand-details" data-section="section1">Learn More</button>
                </div>
                <div class="step">
                    <div class="step-number">2</div>
                    <h3>Edge-Focused Equivalence-Class Test</h3>
                    <p>Cover the valid outputs</p>
                    <button class="btn-secondary expand-details" data-section="section2">Learn More</button>
                </div>
                <div class="step">
                    <div class="step-number">3</div>
                    <h3>Structural Coverage Sweep</h3>
                    <p>Hunt for blind spots</p>
                    <button class="btn-secondary expand-details" data-section="section3">Learn More</button>
                </div>
                <div class="step">
                    <div class="step-number">4</div>
                    <h3>Suite Refinement</h3>
                    <p>Keep what matters, drop the rest</p>
                    <button class="btn-secondary expand-details" data-section="section4">Learn More</button>
                </div>
            </div>
            
            <!-- Expandable Sections -->
            <div class="expandable-sections">
                <div id="section1" class="section-content hidden">
                    <h3>Robust Boundary-Value Tests - Filter Valid vs Invalid</h3>
                    <div class="content-container">
                        <div class="text-content">
                            <p>This approach primarily follows a "guard the gate" strategy. The idea is to rigorously test the transitions between different behavioral conditions by examining values at and around the boundary points of input ranges. These boundaries often represent moments where the program's logic flips, from accepting to rejecting, from true to false, or from one output to another. Testing right at these borders helps confirm that the logic changes when and where it should.</p>

                            <p>This is especially important when working with numeric or ordered inputs, where subtle errors, like off-by-one mistakes or incorrect inequality signs, can cause unexpected or inconsistent behavior. Boundary Value Testing doesn't just aim to catch invalid inputs; it ensures the program behaves predictably and correctly around the edges of decision-making logic.</p>

                            <h4>Systematic Testing Framework</h4>
                            <p>To apply this strategy, we systematically test six values per input variable:</p>

                            <div class="boundary-values">
                                <div class="boundary-value">
                                    <span class="boundary-label">Min - 1:</span>
                                    <span class="boundary-desc">Just below the allowed minimum (should be rejected or behave differently)</span>
                                </div>
                                <div class="boundary-value">
                                    <span class="boundary-label">Min:</span>
                                    <span class="boundary-desc">The exact lower boundary (should be accepted)</span>
                                </div>
                                <div class="boundary-value">
                                    <span class="boundary-label">Min + 1:</span>
                                    <span class="boundary-desc">Just above the lower boundary (should be accepted)</span>
                                </div>
                                <div class="boundary-value">
                                    <span class="boundary-label">Max - 1:</span>
                                    <span class="boundary-desc">Just below the upper boundary (should be accepted)</span>
                                </div>
                                <div class="boundary-value">
                                    <span class="boundary-label">Max:</span>
                                    <span class="boundary-desc">The exact upper boundary (should be accepted)</span>
                                </div>
                                <div class="boundary-value">
                                    <span class="boundary-label">Max + 1:</span>
                                    <span class="boundary-desc">Just above the allowed maximum (should be rejected or behave differently)</span>
                                </div>
                            </div>

                            <p class="insight">This pattern helps verify that the program consistently transitions between states at the correct thresholds and fails gracefully when inputs cross those boundaries. If the program unexpectedly accepts an out-of-range value or rejects a valid boundary value, it likely indicates a logic error that needs further investigation. This systematic method provides clarity and confidence in your program's behavior, especially around critical decision points.</p>
                        </div>
                    </div>
                    <button class="btn-primary section-close">Close</button>
                </div>
                
                <div id="section2" class="section-content hidden">
                    <h3>Edge-Focused Weak Normal Equivalence-Class Tests - Cover Valid Outputs</h3>
                    <div class="content-container">
                        <div class="text-content">
                            <p>The goal of Equivalence Class Testing (ECT) is to verify that a program behaves correctly across distinct categories of input. Rather than testing every possible value, ECT simplifies the process by dividing the input space into groups, called equivalence classes, where all members of a class are expected to produce the same output or behavior. The underlying assumption is that if one representative value from a class behaves correctly, the rest will too. This allows you to reduce the number of test cases while still covering the full range of program behavior.</p>

                            <p>While Boundary Value Testing (BVT) focuses on verifying behavior at the edges of individual conditions, ECT complements this by identifying the broader logic that governs those conditions. Instead of testing just around where the program changes behavior (as in BVT), ECT targets the reason why behavior changes. It helps you define the conditions themselves—mapping out where one class of logic flips to another. In this way, ECT simplifies the challenge of designing BVT cases: once the equivalence classes are defined, you know exactly where transitions occur and where to apply more fine-grained boundary checks.</p>

                            <h4>Implementation Strategy</h4>
                            <p>To implement ECT effectively, follow these three steps:</p>

                            <div class="ect-steps">
                                <div class="ect-step">
                                    <div class="step-number">1</div>
                                    <div class="step-content">
                                        <h5>Partition the input space</h5>
                                        <p>For each input parameter, identify valid and invalid ranges where inputs produce the same type of outcome. Group these into equivalence classes, each defined by producing a unique behavior or result.</p>
                                    </div>
                                </div>

                                <div class="ect-step">
                                    <div class="step-number">2</div>
                                    <div class="step-content">
                                        <h5>Select representative values</h5>
                                        <p>Choose values from each equivalence class that represent the typical or defining behavior of that class. Unlike BVT, the goal isn't to test just inside and outside of a boundary but to test values within each class.</p>
                                    </div>
                                </div>

                                <div class="ect-step">
                                    <div class="step-number">3</div>
                                    <div class="step-content">
                                        <h5>Form test case tuples</h5>
                                        <p>If your function takes multiple inputs, create test cases that combine representatives from different equivalence classes. The goal is to ensure that every combination of classes is tested at least once, providing broad behavioral coverage without unnecessary repetition.</p>
                                    </div>
                                </div>
                            </div>

                            <p class="insight">By designing tests around these representative values and class combinations, you can validate both typical and edge-case behavior while keeping your test suite efficient and targeted. When used alongside BVT, ECT gives you both a high-level map of program logic and the tools to probe its weak points with precision.</p>
                        </div>
                    </div>
                    <button class="btn-primary section-close">Close</button>
                </div>
                
                <div id="section3" class="section-content hidden">
                    <h3>Structural Coverage Sweep - Hunt for Blind Spots</h3>
                    <div class="content-container">
                        <div class="text-content">
                            <p>This strategy focuses on achieving comprehensive test coverage by ensuring that every line of code and every logical branch (i.e., conditionals that can evaluate to true or false) is executed during testing. This is known as line and branch coverage. We use a coverage analysis tool, JaCoCo in our case, to evaluate how thoroughly our test suite exercises the codebase. JaCoCo provides a visual and numerical breakdown of which lines have been executed and whether both the true and false paths of each conditional have been tested.</p>

                            <p>Full branch coverage requires that for every if, else, or logical expression in the code, the test suite must include at least one scenario where the condition evaluates to true and another where it evaluates to false. This guarantees that all possible execution paths are tested, helping to catch bugs that may only arise under specific logical conditions.</p>

                            <div class="coverage-guide">
                                <h4>Understanding JaCoCo Coverage Reports</h4>
                                <p>To implement this strategy, begin by running JaCoCo on your code and reviewing the coverage report it generates. In the report:</p>

                                <div class="coverage-indicators">
                                    <div class="coverage-indicator red">
                                        <div class="color-block red-block"></div>
                                        <div class="indicator-info">
                                            <span class="indicator-label">Red</span>
                                            <span class="indicator-desc">A line or branch that has not been executed at all.</span>
                                        </div>
                                    </div>

                                    <div class="coverage-indicator yellow">
                                        <div class="color-block yellow-block"></div>
                                        <div class="indicator-info">
                                            <span class="indicator-label">Yellow</span>
                                            <span class="indicator-desc">The line was run, but one possible outcome of a conditional has not been tested (e.g., only the "true" case was evaluated).</span>
                                        </div>
                                    </div>

                                    <div class="coverage-indicator green">
                                        <div class="color-block green-block"></div>
                                        <div class="indicator-info">
                                            <span class="indicator-label">Green</span>
                                            <span class="indicator-desc">The line was executed and all conditional outcomes were tested.</span>
                                        </div>
                                    </div>
                                </div>

                                <p>This approach complements both Boundary Value Testing (BVT) and Equivalence Class Testing (ECT) by validating whether the test cases you've written are actually exercising the decision points identified through those strategies. While BVT checks the precise thresholds where program behavior flips and ECT ensures you're testing meaningful categories of input, line and branch coverage confirms that those logical transitions are being activated during execution. In essence, BVT and ECT help you choose the right test cases, and line/branch coverage helps you confirm those tests are hitting all the code paths they need to. Together, they provide a layered approach to robust and meaningful software testing.</p>
                            </div>

                            <h4>Action Plan Based on Coverage Feedback</h4>
                            <ol class="coverage-steps">
                                <li><strong>Identify lines or branches with incomplete coverage.</strong> Look for red and yellow markings in your JaCoCo report.</li>
                                <li><strong>Write targeted test cases that intentionally execute any untested paths</strong> (e.g., force a condition to evaluate to false if only true was tested).</li>
                                <li><strong>Re-run JaCoCo to ensure your tests now fully cover those gaps.</strong> Verify that previously red or yellow sections have turned green.</li>
                            </ol>

                            <p class="insight">Line and branch coverage helps ensure that your program is not only functionally correct under typical inputs but also resilient across edge cases and alternate execution paths. By systematically covering every conditional route, you reduce the risk of silent failures in rarely triggered logic and strengthen the long-term reliability of your codebase.</p>
                        </div>
                    </div>
                    <button class="btn-primary section-close">Close</button>
                </div>
                
                <div id="section4" class="section-content hidden">
                    <h3>Suite Refinement - Keep What Matters, Drop the Rest</h3>
                    <div class="content-container">
                        <div class="text-content">
                            <p>Once you've written a full set of tests, the next step is refinement, eliminating redundancy and clarifying intent. The goal is not to flood your suite with test cases, but to ensure each one serves a unique and meaningful purpose. Redundant tests that verify the same behavior add noise rather than value, and can make your suite harder to interpret or maintain.</p>

                            <div class="refinement-box">
                                <h4>Effective Refinement Process</h4>
                                <p>This phase involves carefully reviewing your test cases and asking: does each one check a different logical path, edge case, or class of input? If multiple tests produce the same result under slightly varied conditions, consider keeping only the most representative example.</p>

                                <div class="naming-examples">
                                    <div class="naming-header">
                                        <i class="fas fa-tags"></i>
                                        <h5>Clear Test Naming</h5>
                                    </div>
                                    <p>It's important to rename your test methods so their purpose is clear to someone reading them for the first time. Descriptive names make it obvious what scenario is being evaluated.</p>

                                    <div class="example-container">
                                        <div class="good-example">
                                            <div class="example-label">Good Examples:</div>
                                            <ul>
                                                <li><code>testRejectsNegativeAgeInput()</code></li>
                                                <li><code>testAcceptsUpperBoundaryValue()</code></li>
                                                <li><code>testHandlesEmptyStringInput()</code></li>
                                            </ul>
                                        </div>

                                        <div class="bad-example">
                                            <div class="example-label">Avoid:</div>
                                            <ul>
                                                <li><code>test1()</code></li>
                                                <li><code>testInput()</code></li>
                                                <li><code>randomTestCase()</code></li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <h4>Key Refinement Strategies</h4>
                            <ul class="strategy-list">
                                <li><i class="fas fa-minus-circle"></i> <span>Eliminate redundant tests that cover the same cases</span></li>
                                <li><i class="fas fa-sort-amount-up"></i> <span>Prioritize tests based on importance and risk</span></li>
                                <li><i class="fas fa-trash-alt"></i> <span>Remove tests that don't add value or coverage</span></li>
                                <li><i class="fas fa-object-group"></i> <span>Combine similar tests for efficiency</span></li>
                                <li><i class="fas fa-folder-tree"></i> <span>Organize tests for better maintainability</span></li>
                            </ul>

                            <p class="insight">In COSC 102, this practice is especially useful for learning to distill complex test coverage into a streamlined, readable, and purposeful suite. Instead of "run-all-the-inputs" brute force, suite refinement teaches you how to test smart—prioritizing clarity and coverage over volume.</p>
                        </div>
                    </div>
                    <button class="btn-primary section-close">Close</button>
                </div>
                
                <div id="section5" class="section-content hidden">
                    <h3>Approach Limitations in Context</h3>
                    <p class="limitations-intro">Our 4-step approach excels at systematically testing functional correctness, but like all methods, it has specific limitations to consider when planning your testing strategy.</p>

                    <div class="limitations-grid">
                        <div class="limitation-card">
                            <div class="limitation-icon">
                                <i class="fas fa-chart-line fa-2x"></i>
                            </div>
                            <h4>Coverage ≠ Completeness</h4>
                            <p>Line/branch coverage only proves every path ran. If you overlook a boundary or mis-group an equivalence class, the suite could still pass while bugs lurk untested. This suite is designed to provide generally sufficient coverage with minimal cases.</p>
                            <div class="limitation-tag">
                                <span>Supplement with:</span> Boundary analysis, equivalence partitioning
                            </div>
                        </div>

                        <div class="limitation-card">
                            <div class="limitation-icon">
                                <i class="fas fa-tasks fa-2x"></i>
                            </div>
                            <h4>Manual Effort Can Scale Rapidly</h4>
                            <p>Drawing boundaries, classes, and crafting extra cases for uncovered branches is quick on small methods but grows increasingly time-consuming with larger functions or deep nesting. We can see the complexity grow quickly with 40 cases for the classify method. While properly written functions should be single-responsibility and lightweight, automated generators or coverage tools can still become necessary.</p>
                            <div class="limitation-tag">
                                <span>Supplement with:</span> Automated test generators, coverage tools
                            </div>
                        </div>

                        <div class="limitation-card">
                            <div class="limitation-icon">
                                <i class="fas fa-cubes fa-2x"></i>
                            </div>
                            <h4>Object-Oriented Programming is Nuanced</h4>
                            <p>Once students reach classes and inheritance, bugs often depend on object state, call sequences, or subclass overrides. The template's single-call focus must be extended to cover those interactions.</p>
                            <div class="limitation-tag">
                                <span>Supplement with:</span> State-based testing, integration testing
                            </div>
                        </div>

                        <div class="limitation-card">
                            <div class="limitation-icon">
                                <i class="fas fa-server fa-2x"></i>
                            </div>
                            <h4>Non-Functional and External Concerns</h4>
                            <p>Performance, randomness, file I/O, and networking calls are not covered by this workflow. Properly testing code that uses these practices may require more complex methods such as mocking. In practice, dependencies that require mocking are present in more advanced code, typically outside the scope of 102 assignments.</p>
                            <div class="limitation-tag">
                                <span>Supplement with:</span> Mocking, performance testing, specialized frameworks
                            </div>
                        </div>
                    </div>

                    <p class="limitations-conclusion">By understanding these limitations, you can better determine when to apply this 4-step approach and when to complement it with other testing strategies for comprehensive quality assurance.</p>

                    <button class="btn-primary section-close">Close</button>
                </div>
            </div>
            
            <div class="cta">
                <h2>Ready to See It in Action?</h2>
                <button class="btn-primary" id="see-in-action">See It In Action</button>
            </div>
            
            <div class="limitations-section">
                <h2>Understanding Approach Limitations</h2>
                <p>Even the best testing approaches have constraints. Being aware of these limitations helps you supplement with other testing methods when necessary.</p>
                <div class="limitations-preview">
                    <div class="limitation-preview-item">
                        <i class="fas fa-chart-line"></i>
                        <p>Coverage ≠ Completeness</p>
                    </div>
                    <div class="limitation-preview-item">
                        <i class="fas fa-tasks"></i>
                        <p>Manual Effort Scaling</p>
                    </div>
                    <div class="limitation-preview-item">
                        <i class="fas fa-cubes"></i>
                        <p>OOP Complexity</p>
                    </div>
                    <div class="limitation-preview-item">
                        <i class="fas fa-server"></i>
                        <p>External Dependencies</p>
                    </div>
                </div>
                <button class="btn-secondary expand-details" data-section="section5">Explore Limitations in Detail</button>
            </div>
        </section>
        
        <!-- Example 1 Page -->
        <section id="example1" class="page">
            <h2>Example 1: Car Simulation - Drive Method</h2>
            <div class="example-overview">
                <p>In this example, we'll walk through the process of testing a car simulation's drive method using our 4-step approach.</p>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">0</div>
                    <h3>Overview</h3>
                </div>
                <div class="step-content">
                    <p>This function is part of a larger program that models a MyCar class, an object-oriented simulation of a car's essential behaviors such as fuel consumption, mileage tracking, and gas refilling. The class includes attributes like fuel efficiency (mpg), gas tank size, total mileage, and gas price, and supports methods that simulate realistic interactions with a car, such as driving, refueling, and maintenance tracking.</p>

                    <p>The driveCar(double miles) method plays a central role in modeling how fuel is consumed when a car is driven. It checks whether the requested number of miles can be driven based on the car's current gas level and miles-per-gallon efficiency. If the request is valid, it updates the fuel level accordingly and returns true; otherwise, it denies the request and returns false. This simple check ensures that the simulation remains realistic, drivers can't magically exceed their car's fuel limits.</p>

                    <p>Testing this method is essential because it represents a core mechanic of the simulation: the link between fuel and distance traveled. If the function allows negative or overly long trips to be recorded, the simulation becomes unrealistic. By applying both Boundary Value Testing and Equivalence Class Testing, we can ensure that the driveCar() method behaves as expected across all relevant input ranges and scenarios, preserving both the integrity and believability of the simulation.</p>

                    <div class="code-example">
                        <h4>The Method We're Testing</h4>
                        <pre><code>
public boolean driveCar(double miles){
    if (miles < 0 || miles > this.mpg*this.currentGas){
        return false;
    }
    this.currentGas = this.currentGas - (miles/this.mpg);
    return true;
}
                        </code></pre>
                    </div>
                </div>
            </div>
            
            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">1</div>
                    <h3>Step 1: Robust Boundary-Value Tests</h3>
                </div>
                <div class="step-content">
                    <p>We want to test the boundaries of the variable miles in this function. To do this, we apply the principles of Boundary Value Testing (BVT), which focuses on values at the very edges of a variable's allowed range—specifically where the program's behavior transitions from one state to another. Rather than merely identifying out-of-bounds errors, BVT is used to verify that logical conditions flip precisely when they're supposed to. These transition points might reflect shifts such as false to true, valid to invalid, or rejected to accepted.</p>

                    <p>In order to isolate the behavior of the miles parameter, we'll fix the other variables in the function to known values. Specifically, we set mpg = 20 and currentGas = 5, which means the maximum drivable distance is 20 * 5 = 100 miles.</p>

                    <p>Now we can systematically test values at and around the key thresholds. Because miles is a double, we can test with precise decimal values, not just whole numbers. This allows us to observe how small variations near those critical boundaries affect program behavior.</p>
                    
                    <h4>Test Cases Created in Step 1</h4>
                    <table>
                        <thead>
                            <tr>
                                <th>Test Case</th>
                                <th>Input (miles)</th>
                                <th>Description</th>
                                <th>Expected Result</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Min - 1: Just below the allowed minimum (should behave differently)</td>
                                <td>-0.1</td>
                                <td>Just below valid range</td>
                                <td>FALSE</td>
                            </tr>
                            <tr>
                                <td>Min - The exact lower boundary (should be accepted)</td>
                                <td>0</td>
                                <td>Lower valid boundary</td>
                                <td>TRUE</td>
                            </tr>
                            <tr>
                                <td>Min + 1 Just above the lower boundary (should be accepted)</td>
                                <td>0.1</td>
                                <td>Slightly above 0</td>
                                <td>TRUE</td>
                            </tr>
                            <tr>
                                <td>Max - 1 Just below the upper boundary (should be accepted)</td>
                                <td>99.9</td>
                                <td>Just below max</td>
                                <td>TRUE</td>
                            </tr>
                            <tr>
                                <td>Max The exact upper boundary (should be accepted)</td>
                                <td>100</td>
                                <td>Upper valid boundary</td>
                                <td>TRUE</td>
                            </tr>
                            <tr>
                                <td>Max + 1 Just above the allowed maximum (should behave differently)</td>
                                <td>100.1</td>
                                <td>Just above max</td>
                                <td>FALSE</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            
            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">2</div>
                    <h3>Step 2: Edge-Focused Weak Normal Equivalence-Class Test</h3>
                </div>
                <div class="step-content">
                    <p>Equivalence Class Testing (ECT) involves dividing input values into categories, or "classes," where all values in a class are expected to produce the same outcome. Rather than testing individual edge values like in BVT, ECT helps ensure the function behaves correctly across broader types of inputs. In the case of driveCar(double miles), we again assume mpg = 20 and currentGas = 5, which means the car can drive a maximum of 100 miles.</p>

                    <p>We can identify the following equivalence classes for the miles input:</p>
                    <ul>
                        <li><strong>EC1:</strong> Negative input values. Any value less than 0 should be considered invalid and return false.</li>
                        <li><strong>EC2:</strong> Valid range values. Any value greater than or equal to 0 but less than or equal to 100 should return true.</li>
                        <li><strong>EC3:</strong> Values exceeding the fuel range. Any value greater than 100 should be considered too far to drive and return false.</li>
                    </ul>

                    <p>To ensure representative coverage across the equivalence classes and validate transitions between them, we design the following four test cases:</p>

                    <h4>Test Cases Created in Step 2</h4>
                    <table>
                        <thead>
                            <tr>
                                <th>Test Case</th>
                                <th>Input (miles)</th>
                                <th>Transitions Between Classes</th>
                                <th>Expected Output</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>1</td>
                                <td>-10</td>
                                <td>Within EC1 (invalid input)</td>
                                <td>FALSE</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>0.1</td>
                                <td>Transition from EC1 → EC2</td>
                                <td>TRUE</td>
                            </tr>
                            <tr>
                                <td>3</td>
                                <td>99.9</td>
                                <td>Within EC2 (valid driving range)</td>
                                <td>TRUE</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>150</td>
                                <td>Transition from EC2 → EC3</td>
                                <td>FALSE</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>These test cases verify that the function correctly interprets inputs from within each behavioral region and handles the transitions across class boundaries appropriately.</p>

                    <p>ECT is most effective when used after BVT has exposed where those behavioral boundaries lie. While BVT stresses the inputs right at the turning points—such as 0.0, 100.0, or just beyond, ECT steps back and ensures each logical region on either side of those boundaries is being properly represented and covered.</p>

                    <p>In this way, building one strategy actually helps inform the construction of the other: BVT pinpoints exactly where logic transitions occur, and ECT maps out the broader regions those transitions define. This allows you to test thoroughly without redundancy, using BVT to confirm precision and ECT to ensure consistent coverage across meaningful input classes.</p>
                </div>
            </div>
            
            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">3</div>
                    <h3>Step 3: Structural Coverage Sweep</h3>
                </div>
                <div class="step-content">
                    <p>Using JaCoCo to analyze our code coverage, we can verify that our test cases from the previous steps provide complete coverage of the driveCar method.</p>

                    <p>The JaCoCo report confirms that our BVT and ECT test cases fully exercise all lines and branches in the method:</p>

                    <div class="coverage-report">
                        <img src="assets/images/ex1_jacoco.png" alt="JaCoCo coverage report for driveCar method" class="coverage-image">
                    </div>

                    <p>As shown in the report, this function is very simple and JaCoCo confirms that it is fully covered by our BVT and ECT test cases. The coverage analysis shows that we've exercised both the true and false conditions of the if statement, ensuring that all execution paths have been tested.</p>
                </div>
            </div>
            
            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">4</div>
                    <h3>Step 4: Suite Refinement</h3>
                </div>
                <div class="step-content">
                    <p>For this simple example, no significant refinement is needed. The driveCar method has straightforward logic with clear boundaries and equivalence classes that we've already covered in our BVT and ECT test cases.</p>

                    <p>Our combined test strategy includes:</p>
                    <ul>
                        <li>Six boundary test cases that verify behavior at and around the minimum (0) and maximum (100) boundaries</li>
                        <li>Four equivalence class test cases that cover the main behavioral regions and transitions between them</li>
                    </ul>

                    <p>JaCoCo confirms we've achieved 100% code coverage, and our tests are minimal and non-redundant. Since this is a simple and straightforward example, there's no need to eliminate redundant tests or optimize our test suite further.</p>
                </div>
            </div>
            
            
            <div class="cta">
                <button class="btn-primary next-example" data-next="example2">Next Example</button>
            </div>
        </section>
        
        <!-- Example 2 Page -->
        <section id="example2" class="page">
            <h2>Example 2: Fantasy Garden Plant Growth</h2>
            <div class="example-overview">
                <p>In this example, we'll test a more complex function with state-dependent behavior and multiple conditions using our 4-step approach.</p>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">0</div>
                    <h3>Function Context</h3>
                </div>
                <div class="step-content">
                    <p>This function comes from the Fantasy Garden project in COSC 102, where students simulate plant growth based on environmental conditions. The simDailyGrowth(int temp, int weather) method models a plant's daily growth depending on both current weather and temperature inputs, but also internal state such as whether the plant is wilted and how many consecutive chilly days have occurred. The function includes several conditional branches and makes use of constants defined in the FantasyGarden class:</p>

                    <pre><code>
// Temperature types
public static final int TEMP_CHILLY = 0;
public static final int TEMP_WARM = 1;
public static final int TEMP_HOT = 2;
// Weather types
public static final int WEATHER_SUNNY = 0;
public static final int WEATHER_CLOUDY = 1;
public static final int WEATHER_RAINY = 2;
                    </code></pre>

                    <p>The growth logic is influenced by whether the plant is already wilted (isWilted()), if the day is chilly, and whether the weather is cloudy or not. If specific chilly and cloudy conditions repeat, the plant may wilt. If the day is suitable, it grows by incrementing previousGrowth. If not, it might reset the growth counter or even return zero. This function illustrates both the challenge of managing internal object state and the complexity introduced when conditions depend on multiple variables interacting.</p>

                    <div class="code-example">
                        <h4>The Function We're Testing</h4>
                        <pre><code>
public int simDailyGrowth(int temp, int weather){
    if (isWilted()){ //if wilted
        return 0;
    }
    if (chillyCounter == 1 && weather == FantasyGarden.TEMP_CHILLY){
        wilt(); //wilted condition
        return WILTED_VALUE;
    } else if (weather != FantasyGarden.WEATHER_CLOUDY){
        chillyCounter = 0;
        previousGrowth += 1;
        return (grow(previousGrowth));
    } else if (chillyCounter != 1 && weather == FantasyGarden.WEATHER_CLOUDY && temp == FantasyGarden.TEMP_CHILLY){
        previousGrowth = 1;
        chillyCounter = 1;
        return (grow(previousGrowth));
    } else if (weather == FantasyGarden.WEATHER_CLOUDY && temp != FantasyGarden.TEMP_CHILLY){
        previousGrowth = 1;
        chillyCounter = 0;
        return grow(previousGrowth);
    }
    return 0;
}
                        </code></pre>
                    </div>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">1</div>
                    <h3>Step 1: Robust Boundary-Value Tests</h3>
                </div>
                <div class="step-content">
                    <p>In this function, boundary value testing isn't about numeric min/max thresholds. Instead, we're testing the logic around conditional transitions, the exact points where the function's behavior flips due to changes in temperature, weather, or internal state. These boundaries may not look like traditional math, but they represent the edges of behavioral change. For example, the plant's transition from healthy to wilted is not determined by a simple number, it's the combination of a specific internal state (chillyCounter == 1) and a triggering input (weather == TEMP_CHILLY).</p>

                    <p>BVT is used here to deliberately probe those transitions: when a plant starts to grow, when it resets its growth cycle, or when it shuts down altogether. We don't need to try every possible input; instead, we construct targeted test cases that sit precisely at those flip points. These are the decision thresholds where the program's return value will change based on just one piece of input.</p>

                    <p>For example:</p>
                    <ul>
                        <li>Case 2 tests the moment when the plant switches from being on the edge of wilting to actually wilting. This is only triggered under very specific conditions (counter = 1 and weather = TEMP_CHILLY). Note that in the code, TEMP_CHILLY is the constant value 0, which might be confusing since we also use 0 for temperature values.</li>
                        <li>Case 4 confirms that non-chilly temperatures on cloudy days do not cause wilting, helping isolate the logic that distinguishes these similar but subtly different paths.</li>
                        <li>Each test case uses a fresh Plant instance to avoid state contamination between tests, which was critical for tests 3 and 5.</li>
                    </ul>

                    <h4>Test Cases Created in Step 1</h4>
                    <table>
                        <thead>
                            <tr>
                                <th>Test Case</th>
                                <th>temp</th>
                                <th>weather</th>
                                <th>Internal State</th>
                                <th>Description</th>
                                <th>Expected Output</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>1</td>
                                <td>0</td>
                                <td>1</td>
                                <td>wilted=true</td>
                                <td>Already wilted plant</td>
                                <td>0</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>0</td>
                                <td>0</td>
                                <td>counter=1, fresh Plant</td>
                                <td>Repeated chilly days trigger wilt</td>
                                <td>WILTED_VALUE</td>
                            </tr>
                            <tr>
                                <td>3</td>
                                <td>0</td>
                                <td>1</td>
                                <td>counter=0, fresh Plant</td>
                                <td>Cloudy + chilly sets up counter = 1</td>
                                <td>grow(1)</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>1</td>
                                <td>1</td>
                                <td>counter=0, fresh Plant</td>
                                <td>Cloudy + warm resets counter = 0</td>
                                <td>grow(1)</td>
                            </tr>
                            <tr>
                                <td>5</td>
                                <td>1</td>
                                <td>2</td>
                                <td>counter=1, previousGrowth=1, fresh Plant</td>
                                <td>Rainy + warm day, increments growth</td>
                                <td>grow(2)</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>This focused approach lets us quickly confirm that all logical gates in the function work properly without needing a bloated test suite. It emphasizes precision over repetition.</p>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">2</div>
                    <h3>Step 2: Edge-Focused Weak Normal Equivalence-Class Test</h3>
                </div>
                <div class="step-content">
                    <p>Here we categorize input scenarios that result in consistent behavior and group them into equivalence classes. These categories help simplify the testing process by covering more ground with fewer cases. Instead of trying every single permutation of temp, weather, and internal state, we select one representative input for each class that exhibits a unique behavior pattern. This function presents a classic case where internal state influences outcomes just as much as input parameters. For example, a test where temp = TEMP_CHILLY and weather = WEATHER_CLOUDY might result in different outcomes depending on whether chillyCounter is 0 or 1. That's why our equivalence classes take both current inputs and the plant's internal memory into account.</p>

                    <p>Each test here is chosen to represent a class of behavior, not just a unique line of code:</p>
                    <ul>
                        <li>EC1 is a hard stop: once a plant is wilted, nothing else matters, it always returns 0.</li>
                        <li>EC3 and EC4 both deal with cloudy days, but the difference in temperature causes very different logic to execute. These are tested separately because they reflect two distinct branches of the function.</li>
                        <li>EC5 captures all non-cloudy weather outcomes where growth should continue, offering a broader behavioral region that's consistent in logic.</li>
                    </ul>

                    <h4>Equivalence Classes for simDailyGrowth</h4>
                    <table>
                        <thead>
                            <tr>
                                <th>Class ID</th>
                                <th>Description</th>
                                <th>Input/State Conditions</th>
                                <th>Expected Behavior</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>EC1</td>
                                <td>Already wilted plant</td>
                                <td>isWilted() == true</td>
                                <td>Return 0 (no growth)</td>
                            </tr>
                            <tr>
                                <td>EC2</td>
                                <td>Plant about to wilt</td>
                                <td>chillyCounter == 1 & current weather is chilly</td>
                                <td>Return wilted value</td>
                            </tr>
                            <tr>
                                <td>EC3</td>
                                <td>First chilly, cloudy day</td>
                                <td>chillyCounter == 0 & weather == CLOUDY & temp == CHILLY</td>
                                <td>Set chillyCounter = 1, Return grow(1)</td>
                            </tr>
                            <tr>
                                <td>EC4</td>
                                <td>Cloudy but not chilly</td>
                                <td>weather == CLOUDY & temp != CHILLY</td>
                                <td>Reset chillyCounter, Return grow(1)</td>
                            </tr>
                            <tr>
                                <td>EC5</td>
                                <td>Not cloudy weather</td>
                                <td>weather != CLOUDY</td>
                                <td>Reset chillyCounter, grow by previousGrowth+1</td>
                            </tr>
                        </tbody>
                    </table>

                    <h4>Test Cases Created in Step 2</h4>
                    <table>
                        <thead>
                            <tr>
                                <th>Test Case</th>
                                <th>Input Values</th>
                                <th>Equivalence Class</th>
                                <th>Expected Result</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>ECT1</td>
                                <td>Any values, wilted = true, fresh Plant</td>
                                <td>EC1</td>
                                <td>0</td>
                            </tr>
                            <tr>
                                <td>ECT2</td>
                                <td>temp = 0, weather = 0, counter = 1, fresh Plant</td>
                                <td>EC2</td>
                                <td>WILTED_VALUE</td>
                            </tr>
                            <tr>
                                <td>ECT3</td>
                                <td>temp = 0, weather = 1, counter = 0, fresh Plant</td>
                                <td>EC3</td>
                                <td>grow(1)</td>
                            </tr>
                            <tr>
                                <td>ECT4</td>
                                <td>temp = 1, weather = 1, counter = 0, fresh Plant</td>
                                <td>EC4</td>
                                <td>grow(1)</td>
                            </tr>
                            <tr>
                                <td>ECT5</td>
                                <td>temp = 1, weather = 2, previousGrowth = 3, fresh Plant</td>
                                <td>EC5</td>
                                <td>grow(4)</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>By clearly separating these equivalence classes and testing only once per class, we avoid redundancy while still ensuring total behavioral coverage. It's a high-efficiency way to confirm that each type of scenario behaves as expected without overwhelming the test suite with duplicates.</p>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">3</div>
                    <h3>Step 3: Structural Coverage Sweep</h3>
                </div>
                <div class="step-content">
                    <p>After running our BVT and ECT tests through JaCoCo, we found that there was still one line of code that wasn't being executed at all (shown in red in the JaCoCo report):</p>

                    <ul>
                        <li>The final return 0 statement at the bottom was never executed (red line)</li>
                        <li>This represents an important edge case in our ECT that we missed in our original analysis</li>
                        <li>While there was also yellow highlighting for some conditions, we're primarily focused on achieving line and branch coverage at this stage, not condition coverage</li>
                    </ul>

                    <p>To achieve complete line and branch coverage, we added a specific test to target the red line (the uncovered fall-through path):</p>

                    <div class="coverage-table">
                        <table>
                            <thead>
                                <tr>
                                    <th>Test ID</th>
                                    <th>Inputs</th>
                                    <th>Internal State</th>
                                    <th>Purpose</th>
                                    <th>Expected Result</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>SC1</td>
                                    <td>temp=TEMP_CHILLY (0), weather=WEATHER_CLOUDY (1)</td>
                                    <td>counter=1, fresh Plant</td>
                                    <td>Test cloudy+chilly with counter=1 fallthrough path</td>
                                    <td>0</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <p>The JaCoCo report now confirms that with our complete test suite, we've eliminated all red lines, achieving full line and branch coverage for the simDailyGrowth method. This test case was essential because it represents a missed equivalence class in our earlier analysis - a case where the plant has a chillyCounter of 1 on a cloudy, chilly day but doesn't wilt:</p>

                    <div class="coverage-report">
                        <img src="assets/images/ex2_jacoco.png" alt="JaCoCo coverage report for simDailyGrowth method" class="coverage-image">
                    </div>

                    <p>As shown in the report, all lines of code are now exercised, with no red lines remaining. Upon rerunning JaCoCo with our updated test suite, the previously missed return line (line 671) turned green. While some conditions may still show yellow highlighting (indicating that not all possible boolean combinations were tested), we've achieved our primary goal of ensuring every line of code and every branch is exercised at least once. This highlights why JaCoCo is such a valuable final check - it revealed a meaningful edge case that our ECT analysis had overlooked.</p>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">4</div>
                    <h3>Step 4: Suite Refinement</h3>
                </div>
                <div class="step-content">
                    <p>After examining our complete test suite, we can make the following refinements:</p>

                    <ol>
                        <li>Eliminate redundancy: EC1-A duplicates BVT Case 1, so we can remove one of them</li>
                        <li>Combine similar cases: EC2-A and BVT Case 3 test the same condition, so we can merge them</li>
                        <li>Prioritize the most revealing tests: The wilting transition tests are particularly important</li>
                    </ol>

                    <p>Here is our complete comprehensive test suite for the simDailyGrowth function, organized by test type and showing the priority of each test:</p>

                    <table>
                        <thead>
                            <tr>
                                <th>Test ID</th>
                                <th>Test Type</th>
                                <th>Description</th>
                                <th>Inputs</th>
                                <th>Priority</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>BVT1</td>
                                <td>Boundary Value</td>
                                <td>Already wilted plant behavior</td>
                                <td>wilted=true, any temp/weather</td>
                                <td>Medium</td>
                            </tr>
                            <tr>
                                <td>BVT2</td>
                                <td>Boundary Value</td>
                                <td>Wilting transition</td>
                                <td>temp=CHILLY, weather=TEMP_CHILLY, counter=1, fresh Plant</td>
                                <td>High</td>
                            </tr>
                            <tr>
                                <td>BVT3</td>
                                <td>Boundary Value</td>
                                <td>First chilly+cloudy day</td>
                                <td>temp=CHILLY, weather=CLOUDY, counter=0, fresh Plant</td>
                                <td>Medium</td>
                            </tr>
                            <tr>
                                <td>BVT5</td>
                                <td>Boundary Value</td>
                                <td>Growth increment</td>
                                <td>temp=WARM, weather=RAINY, counter=1, previousGrowth=1, fresh Plant</td>
                                <td>High</td>
                            </tr>
                            <tr>
                                <td>ECT1</td>
                                <td>Equivalence Class</td>
                                <td>Warm weather growth</td>
                                <td>temp=WARM, weather=SUNNY, fresh Plant</td>
                                <td>Medium</td>
                            </tr>
                            <tr>
                                <td>ECT3</td>
                                <td>Equivalence Class</td>
                                <td>Non-chilly cloudy day</td>
                                <td>temp=HOT, weather=CLOUDY, fresh Plant</td>
                                <td>Medium</td>
                            </tr>
                            <tr>
                                <td>SC1</td>
                                <td>Structural Coverage</td>
                                <td>Cloudy+chilly fallthrough</td>
                                <td>temp=TEMP_CHILLY (0), weather=WEATHER_CLOUDY (1), counter=1</td>
                                <td>Low</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>This refined suite balances thorough coverage with efficiency, focusing on the most important behavioral aspects while still ensuring all code paths are tested at least once. By eliminating redundant tests and prioritizing the most critical scenarios, we've created a test suite that efficiently validates the simDailyGrowth function's behavior across all its logical boundaries.</p>
                </div>
            </div>


            <div class="cta">
                <button class="btn-primary next-example" data-next="example3">Next Example</button>
            </div>
        </section>
        
        <!-- Example 3 Page -->
        <section id="example3" class="page">
            <h2>Example 3: Wordle-style Game Mechanic</h2>
            <div class="example-overview">
                <p>In this example, we'll apply our 4-step approach to test a function that supports a Wordle-style game mechanic, which compares guessed letters with a secret word and provides color-coded feedback.</p>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">0</div>
                    <h3>Function Context</h3>
                </div>
                <div class="step-content">
                    <p>This function supports a Wordle-style game mechanic. It compares the guessed letter at index j in the current row with the secret word's character at the same index. If the characters match exactly, the tile is colored green and the rightSpot counter is incremented. If the guessed character exists elsewhere in the secret word (but not at the current index), the tile is colored yellow unless it's already marked green. If the guessed character is not in the secret word at all, the tile is colored gray.</p>

                    <div class="code-example">
                        <h4>The Function We're Testing</h4>
                        <pre><code>
public static int checkLetters(int j, int rightSpot){ //compares the guessed word to the secret word
    char wordLetter = GameGUI.getSecretWordArr()[j]; //gets letter from answer word
    char guessLetter = GameGUI.getGridChar(currentRow, j); //gets letter in the spot
          if (wordLetter == guessLetter){ //colors in boxes if leters are equal
                GameGUI.setGridColor(currentRow, j, CORRECT_COLOR); //sets color to green
                GameGUI.setKeyColor(wordLetter, CORRECT_COLOR);
                rightSpot += 1; // is this guess correct for the secret at this spot, if it is then we color and are done, if it is not then we need to differentiate between yellow and dark gray
             }else{
                for (int i = 0; i< MAX_COLS; i++){
                   if (guessLetter == GameGUI.getSecretWordArr()[i]){
                      GameGUI.setGridColor(currentRow, j, WRONG_PLACE_COLOR);
                      if (GameGUI.getKeyColor(guessLetter) != CORRECT_COLOR){
                         GameGUI.setKeyColor(guessLetter, WRONG_PLACE_COLOR);
                      }
                   } else if (GameGUI.getKeyColor(guessLetter) != WRONG_PLACE_COLOR && GameGUI.getKeyColor(guessLetter) != CORRECT_COLOR){
                      GameGUI.setKeyColor(guessLetter, WRONG_COLOR);
                   }

                   }
                }
             return rightSpot;
          }
                        </code></pre>
                    </div>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">1</div>
                    <h3>Step 1: Robust Boundary-Value Tests</h3>
                </div>
                <div class="step-content">
                    <p>This problem has two dimensions that influence the function's behavior: the index j and the guessed word itself. To thoroughly apply Boundary Value Testing, we isolate each of these variables and test how the logic transitions as we move across their respective boundaries. First, we hold the index constant and vary the guessed letter to reveal how matches, near-matches, and mismatches affect the outcome. Next, we hold the guessed word constant and vary the index to examine how the same characters behave across different positions in the word.</p>

                    <p>This two-dimensional BVT approach demonstrates how we can apply boundary testing not only across numeric thresholds, but across distinct control flow transitions, validating correctness from multiple interacting angles.</p>

                    <h4>Equivalence Classes for checkLetters</h4>
                    <table>
                        <thead>
                            <tr>
                                <th>Class</th>
                                <th>Condition</th>
                                <th>Description</th>
                                <th>Expected Behavior</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>EC1</td>
                                <td>guess[j] == secret[j]</td>
                                <td>exact match</td>
                                <td>green, increment rightSpot</td>
                            </tr>
                            <tr>
                                <td>EC2</td>
                                <td>guess[j] != secret[j] && guess[j] in secret</td>
                                <td>in word but wrong position</td>
                                <td>yellow, rightSpot unchanged</td>
                            </tr>
                            <tr>
                                <td>EC3</td>
                                <td>guess[j] not in secret</td>
                                <td>completely incorrect</td>
                                <td>gray, rightSpot unchanged</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>These values represent boundaries between green → yellow → gray transitions, based on exact character alignment and word inclusion. We keep the index constant (j = 0) and vary only the guessed letter to examine how the output behavior changes across key logical transitions: an exact match, a letter in the word but in the wrong position, and a letter not in the word at all.</p>

                    <p>This isolation allows us to precisely identify the boundaries that shift the program from one behavior (green coloring and incrementing rightSpot) to another (yellow or gray coloring with no increment). Boundary Value Testing is not limited to numeric comparisons; it can be extended to categorical logic, such as character string comparisons and boolean condition transitions, wherever a meaningful behavioral boundary exists.</p>

                    <h4>Test Cases Created in Step 1 - Dimension 1: Character Variation</h4>
                    <p>For these tests, we hold the index constant (j = 0) and vary only the guessed letter to examine how the output behavior changes across the key logical transitions.</p>

                    <table>
                        <thead>
                            <tr>
                                <th>Test ID</th>
                                <th>Secret Word</th>
                                <th>Guessed Word</th>
                                <th>Index (j)</th>
                                <th>Expected Behavior</th>
                                <th>Boundary Being Tested</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>BVT1</td>
                                <td>"CRANE"</td>
                                <td>"CRASS"</td>
                                <td>0</td>
                                <td>Green, rightSpot++</td>
                                <td>'C' exact match (EC1)</td>
                            </tr>
                            <tr>
                                <td>BVT2</td>
                                <td>"CRANE"</td>
                                <td>"EATER"</td>
                                <td>0</td>
                                <td>Yellow, rightSpot unchanged</td>
                                <td>'E' in word but wrong position (EC2)</td>
                            </tr>
                            <tr>
                                <td>BVT3</td>
                                <td>"CRANE"</td>
                                <td>"PRANK"</td>
                                <td>0</td>
                                <td>Gray, rightSpot unchanged</td>
                                <td>'P' not in word (EC3)</td>
                            </tr>
                        </tbody>
                    </table>

                    <h4>Test Cases Created in Step 1 - Dimension 2: Position Variation</h4>
                    <p>We then shift focus to the second dimension, position. By keeping the guess word constant and varying the index j, we test how the function applies the same comparison logic across multiple positions in the word. Using a partially overlapping word like "CRASS" against the secret word "CRANE" allows us to track how the same letter behaves differently depending on its position.</p>

                    <table>
                        <thead>
                            <tr>
                                <th>Test ID</th>
                                <th>Secret Word</th>
                                <th>Guessed Word</th>
                                <th>Index (j)</th>
                                <th>Expected Behavior</th>
                                <th>Boundary Being Tested</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>BVT4</td>
                                <td>"CRANE"</td>
                                <td>"CRASS"</td>
                                <td>0</td>
                                <td>Green, rightSpot++</td>
                                <td>'C' at correct position (EC1)</td>
                            </tr>
                            <tr>
                                <td>BVT5</td>
                                <td>"CRANE"</td>
                                <td>"SCARS"</td>
                                <td>1</td>
                                <td>Gray, rightSpot unchanged</td>
                                <td>'C' at wrong position, but not in word at that position (EC3)</td>
                            </tr>
                            <tr>
                                <td>BVT6</td>
                                <td>"CRANE"</td>
                                <td>"TEACH"</td>
                                <td>2</td>
                                <td>Yellow, rightSpot unchanged</td>
                                <td>'A' at wrong position, but in word elsewhere (EC2)</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>To make this truly reflect Boundary Value Testing, we observe how the same guessed letter produces different behavior at different positions. For example, the character 'C' appears in both guess words, "CRASS" and "SCARS", but at different indices. In "CRASS", it aligns with the same position in the secret word (index 0), triggering a correct match (green). In "SCARS", the same 'C' appears at index 1, which does not match the corresponding character in the secret word, resulting in gray. This demonstrates that the function's output is not solely determined by the presence of the letter but also by its position.</p>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">2</div>
                    <h3>Step 2: Edge-Focused Weak Normal Equivalence-Class Test</h3>
                </div>
                <div class="step-content">
                    <p>While BVT focuses on finding the precise transition points in logic, ECT helps validate the consistency of behavior within those broader regions. It is most effective when used after BVT has mapped out where those boundaries occur. For example, once BVT shows that the function transitions from green to yellow when the guessed letter changes or moves, ECT ensures that any value that falls into the "green" or "yellow" category behaves as expected, regardless of the specific input.</p>

                    <p>In the case of checkLetters, BVT helps identify that the output changes based on character match and position. ECT then groups those outcomes into logical classes—exact match, partial match, and no match—and checks whether the function treats all members of each class consistently. This layered approach reduces redundancy while improving coverage: BVT highlights the edges, and ECT confirms the rules within each region.</p>

                    <ol>
                        <li><strong>EC1: Exact Character Match</strong> - The guessed letter matches the secret letter at the same position</li>
                        <li><strong>EC2: Character in Word but Wrong Position</strong> - The guessed letter exists in the secret word but not at the current position</li>
                        <li><strong>EC3: Character Not in Word</strong> - The guessed letter does not appear anywhere in the secret word</li>
                    </ol>

                    <p>Now we'll create test cases that represent each equivalence class, ensuring that all types of character matches are properly handled by the function.</p>

                    <h4>Test Cases Created in Step 2</h4>
                    <table>
                        <thead>
                            <tr>
                                <th>Test ID</th>
                                <th>Secret Word</th>
                                <th>Guessed Word</th>
                                <th>Description</th>
                                <th>Equivalence Class</th>
                                <th>Expected Behavior</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>ECT1</td>
                                <td>"BRAVE"</td>
                                <td>"BROKE"</td>
                                <td>First two letters match exactly</td>
                                <td>EC1 (for j=0, j=1)</td>
                                <td>Green for 'B' and 'R', rightSpot+=2</td>
                            </tr>
                            <tr>
                                <td>ECT2</td>
                                <td>"BRAVE"</td>
                                <td>"EARNS"</td>
                                <td>Contains 'A', 'E', 'R' in wrong positions</td>
                                <td>EC2 (for multiple j)</td>
                                <td>Yellow for 'A', 'E', 'R', rightSpot unchanged</td>
                            </tr>
                            <tr>
                                <td>ECT3</td>
                                <td>"BRAVE"</td>
                                <td>"CLOCK"</td>
                                <td>Contains no letters from the secret word</td>
                                <td>EC3 (for all j)</td>
                                <td>Gray for all letters, rightSpot unchanged</td>
                            </tr>
                            <tr>
                                <td>ECT4</td>
                                <td>"BRAVE"</td>
                                <td>"VALVE"</td>
                                <td>Mixed case: 'V' and 'E' match at right position, 'A' exists but wrong position</td>
                                <td>Mix of EC1 and EC2</td>
                                <td>Green for 'V' and 'E', yellow for 'A', gray for 'L', rightSpot+=2</td>
                            </tr>
                            <tr>
                                <td>ECT5</td>
                                <td>"SPEED"</td>
                                <td>"SPELL"</td>
                                <td>Multiple instances: 'S','P','E' match at positions 0,1,2, second 'E' (in SPEED) not matched</td>
                                <td>Multiple instances of EC1</td>
                                <td>Green for 'S', 'P', 'E', gray for 'L', 'L', rightSpot+=3</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>By using ECT to sweep across each class, we confirm that the function applies the same logic to any input that falls within a class—ensuring reliability and coherence in its behavior. This approach provides broad coverage while keeping our test suite manageable.</p>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">3</div>
                    <h3>Step 3: Structural Coverage Sweep</h3>
                </div>
                <div class="step-content">
                    <p>After running our BVT and ECT tests, we analyzed our code coverage to identify any untested paths. We found a few edge cases that needed additional testing:</p>

                    <ul>
                        <li>The case where a letter appears multiple times in the secret word</li>
                        <li>The case where a guessed letter already has a green color from a previous check</li>
                        <li>The case where a guessed letter already has a yellow color from a previous check</li>
                    </ul>

                    <p>To ensure complete branch coverage, we added these additional test cases:</p>

                    <div class="coverage-table">
                        <table>
                            <thead>
                                <tr>
                                    <th>Test ID</th>
                                    <th>Secret Word</th>
                                    <th>Guessed Word</th>
                                    <th>Purpose</th>
                                    <th>Expected Result</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>SC1</td>
                                    <td>"SWEET"</td>
                                    <td>"STEEL"</td>
                                    <td>Test handling of duplicate letters ('E' appears twice in secret)</td>
                                    <td>Green for 'S', 'E', yellow for other 'E', gray for others</td>
                                </tr>
                                <tr>
                                    <td>SC2</td>
                                    <td>"BOATS"</td>
                                    <td>"FLOAT"</td>
                                    <td>Test key coloring logic where some keys already have colors</td>
                                    <td>Complex key color state check</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <p>The JaCoCo coverage report confirms that with our combined test suite, we've achieved complete branch coverage for the checkLetters method:</p>

                    <div class="coverage-report">
                        <img src="assets/images/ex3_jacoco.png" alt="JaCoCo coverage report for checkLetters method" class="coverage-image">
                    </div>

                    <p>The report shows that all branches of the conditional logic are covered, including the special case handling for colors that have already been assigned. This ensures we've exercised all possible execution paths through the function.</p>
                </div>
            </div>

            <div class="approach-step">
                <div class="step-header">
                    <div class="step-number">4</div>
                    <h3>Step 4: Suite Refinement</h3>
                </div>
                <div class="step-content">
                    <p>After examining our complete test suite, we identified opportunities to eliminate redundancy while maintaining comprehensive coverage:</p>

                    <ol>
                        <li>We can combine some of our position-specific tests that test similar behaviors</li>
                        <li>We can reduce the number of similar yellow-case tests since they exercise the same code path</li>
                        <li>We need to prioritize tests that exercise complex state transitions in the keyboard coloring logic</li>
                    </ol>

                    <p>Here is our complete comprehensive test suite for the checkLetters function, organized by test type and showing all key test cases:</p>

                    <table>
                        <thead>
                            <tr>
                                <th>Test ID</th>
                                <th>Test Type</th>
                                <th>Secret Word</th>
                                <th>Guessed Word</th>
                                <th>Description</th>
                                <th>Priority</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>BVT1</td>
                                <td>Boundary Value</td>
                                <td>"CRANE"</td>
                                <td>"CRASS"</td>
                                <td>Exact match transition (green)</td>
                                <td>High</td>
                            </tr>
                            <tr>
                                <td>BVT3</td>
                                <td>Boundary Value</td>
                                <td>"CRANE"</td>
                                <td>"PRANK"</td>
                                <td>Complete miss transition (gray)</td>
                                <td>High</td>
                            </tr>
                            <tr>
                                <td>BVT6</td>
                                <td>Boundary Value</td>
                                <td>"CRANE"</td>
                                <td>"TEACH"</td>
                                <td>Yellow case - letter in word but wrong position</td>
                                <td>High</td>
                            </tr>
                            <tr>
                                <td>ECT1</td>
                                <td>Equivalence Class</td>
                                <td>"BRAVE"</td>
                                <td>"BROKE"</td>
                                <td>Multiple exact matches (green)</td>
                                <td>Medium</td>
                            </tr>
                            <tr>
                                <td>ECT2</td>
                                <td>Equivalence Class</td>
                                <td>"BRAVE"</td>
                                <td>"EARNS"</td>
                                <td>Multiple letters in wrong positions (yellow)</td>
                                <td>Medium</td>
                            </tr>
                            <tr>
                                <td>ECT3</td>
                                <td>Equivalence Class</td>
                                <td>"BRAVE"</td>
                                <td>"CLOCK"</td>
                                <td>Complete miss case (all gray)</td>
                                <td>Medium</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>This refined suite balances thorough coverage with efficiency, focusing on the most important behavioral aspects while still ensuring all code paths are tested at least once. By organizing our tests in this way, we can quickly see which aspects of the function are most thoroughly tested and which critical behaviors are verified. The high-priority tests capture the essential transition points between the three color states (green, yellow, gray), while the medium and low-priority tests ensure complete coverage of edge cases and defensive code.</p>
                </div>
            </div>

        </section>
        
        <!-- Advanced Page - Maven & JaCoCo Blog-Style -->
        <section id="advanced" class="page">
            <h2>Advanced Testing Tools</h2>
            <div class="example-overview">
                <p>Setting up a robust testing environment is essential for effective test-driven development. Learn how to leverage Maven and JaCoCo to streamline your testing workflow.</p>
            </div>

            <div class="approach-step blog-post">
                <div class="blog-header">
                    <h3>Maven & JaCoCo: Your Complete Testing Toolkit</h3>
                </div>

                <div class="blog-content">
                    <p>Maven is the build engine that fetches your dependencies, compiles your code, runs every JUnit test, and—thanks to the bundled JaCoCo plug‑in—spits out a line‑by‑line coverage report in HTML. Getting that toolchain wired up from scratch can be a headache, but don't worry, we've got you covered.</p>

                    <h4>Quick Start Guide</h4>
                    <div class="steps-container">
                        <div class="step-item">
                            <div class="step-icon"><i class="fas fa-code-branch"></i></div>
                            <div class="step-content">
                                <h5>1. Clone the Repository</h5>
                                <p>Clone the ready‑made harness at <a href="https://github.com/jon-cook1/102-coverage" target="_blank">https://github.com/jon-cook1/102-coverage</a> into the folder that sits next to your lab.</p>
                                <div class="code-example">
                                    <pre><code>git clone https://github.com/jon-cook1/102-coverage</code></pre>
                                </div>
                            </div>
                        </div>

                        <div class="step-item">
                            <div class="step-icon"><i class="fas fa-cogs"></i></div>
                            <div class="step-content">
                                <h5>2. Set Up the Testing Environment</h5>
                                <p>Run the setup script once to configure the testing environment for your lab.</p>
                                <div class="code-example">
                                    <pre><code>./setup_tests.sh ../YourLabFolder</code></pre>
                                </div>
                            </div>
                        </div>

                        <div class="step-item">
                            <div class="step-icon"><i class="fas fa-vial"></i></div>
                            <div class="step-content">
                                <h5>3. Run Your Tests</h5>
                                <p>After the initial setup, just call the run script whenever you want fresh results.</p>
                                <div class="code-example">
                                    <pre><code>./run_tests.sh</code></pre>
                                </div>
                            </div>
                        </div>

                        <div class="step-item">
                            <div class="step-icon"><i class="fas fa-sync-alt"></i></div>
                            <div class="step-content">
                                <h5>4. Testing a Different Project</h5>
                                <p>Need to test a different project? Just rerun the setup script with the new folder path.</p>
                                <div class="code-example">
                                    <pre><code>./setup_tests.sh ../NewLabFolder</code></pre>
                                </div>
                                <p class="note"><i class="fas fa-info-circle"></i> Note: Changing labs wipes the tests already inside the harness, because this beta is meant as a quick‑start demo rather than a permanent test repository.</p>
                            </div>
                        </div>
                    </div>

                    <div class="info-box">
                        <div class="info-icon"><i class="fas fa-lightbulb"></i></div>
                        <div class="info-content">
                            <h4>How It Works</h4>
                            <p>The 102-coverage harness automates the entire testing process:</p>
                            <ul>
                                <li>Configures Maven to work with your Java project</li>
                                <li>Sets up JUnit test execution</li>
                                <li>Integrates JaCoCo for code coverage analysis</li>
                                <li>Generates HTML reports showing your test coverage</li>
                                <li>Provides a simple interface to run and view test results</li>
                            </ul>
                            <p>Full step‑by‑step instructions are available in the repo's README.</p>
                        </div>
                    </div>

                    <div class="tool-showcase">
                        <div class="tool-item">
                            <div class="tool-icon"><i class="fas fa-box"></i></div>
                            <h4>Maven</h4>
                            <p>Industry-standard build tool that manages dependencies, compiles code, and runs tests with a simple command.</p>
                        </div>

                        <div class="tool-item">
                            <div class="tool-icon"><i class="fas fa-chart-pie"></i></div>
                            <h4>JaCoCo</h4>
                            <p>Code coverage library that shows exactly which lines of your code are tested and which are not, with intuitive visual reports.</p>
                        </div>
                    </div>

                </div>
            </div>

            <div class="cta">
                <h3>Ready to Improve Your Test Coverage?</h3>
                <div class="button-container">
                    <a href="https://github.com/jon-cook1/102-coverage" target="_blank" class="btn-primary">
                        <i class="fas fa-code-branch"></i> Go to Repository
                    </a>
                    <a href="https://github.com/jon-cook1/102-coverage#readme" target="_blank" class="btn-secondary">
                        <i class="fas fa-book"></i> View Setup Instructions
                    </a>
                </div>
            </div>
        </section>
    </main>
    
    <footer>
        <div class="footer-content">
            <p>&copy; 2025 COSC 102 Testing Guide</p>
            <p>Created for educational purposes</p>
        </div>
    </footer>
    
    <script src="assets/js/main.js"></script>
</body>
</html>